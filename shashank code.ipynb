{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUQmZedxvoNFSFOMcSEd3F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A51621/2303A51621-batch-22/blob/main/shashank%20code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bw880Y5aCP6d",
        "outputId": "81b763a6-9aed-4665-93ce-99d955551ed6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3773073736.py:80: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
            "  plt.boxplot(grouped, labels=labels, showmeans=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.295\n",
            "Precision (macro): 0.29515745692216283\n",
            "Recall (macro): 0.2950399517563696\n",
            "F1 (macro): 0.2950878880703442\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        high       0.28      0.28      0.28        67\n",
            "         low       0.30      0.30      0.30        67\n",
            "      medium       0.30      0.30      0.30        66\n",
            "\n",
            "    accuracy                           0.29       200\n",
            "   macro avg       0.30      0.30      0.30       200\n",
            "weighted avg       0.30      0.29      0.30       200\n",
            "\n",
            "\n",
            "Saved:\n",
            "- fig1.png\n",
            "- fig2.png\n",
            "- fig3.png\n",
            "- classification_report.txt\n",
            "- confusion_matrix.csv\n",
            "- feature_importances.csv\n"
          ]
        }
      ],
      "source": [
        "# edu_inequality_pipeline.py\n",
        "# Comprehensive pipeline for “Educational Inequality” analysis + ML\n",
        "# - EDA: correlation heatmap, funding distribution by school_type\n",
        "# - ML: RandomForest to predict dropout risk (low/medium/high)\n",
        "# - Outputs: fig1.png, fig2.png, fig3.png + metrics/report CSVs\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report\n",
        ")\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# 0) Paths (edit if running locally)\n",
        "# -------------------------------------------------------\n",
        "ZIP_PATH = \"/content/archive (1).zip\"  # change or skip if already extracted\n",
        "EXTRACT_DIR = \"extracted_dataset\"\n",
        "DATA_PATH = os.path.join(EXTRACT_DIR, \"education_inequality_data.csv\")\n",
        "\n",
        "FIG1 = \"fig1.png\"  # correlation heatmap\n",
        "FIG2 = \"fig2.png\"  # funding distribution by school type (boxplot)\n",
        "FIG3 = \"fig3.png\"  # model performance bar chart\n",
        "\n",
        "REPORT_TXT = \"classification_report.txt\"\n",
        "CM_CSV = \"confusion_matrix.csv\"\n",
        "FEATIMP_CSV = \"feature_importances.csv\"\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# 1) Extract (if needed) and load dataset\n",
        "# -------------------------------------------------------\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    if os.path.exists(ZIP_PATH):\n",
        "        os.makedirs(EXTRACT_DIR, exist_ok=True)\n",
        "        with zipfile.ZipFile(ZIP_PATH, \"r\") as z:\n",
        "            z.extractall(EXTRACT_DIR)\n",
        "    else:\n",
        "        raise FileNotFoundError(\n",
        "            f\"Dataset not found at {DATA_PATH} and ZIP not present at {ZIP_PATH}.\"\n",
        "        )\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# 2) EDA: Correlation heatmap of numeric features\n",
        "# -------------------------------------------------------\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "corr = df[numeric_cols].corr()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.imshow(corr, interpolation=\"nearest\")  # no explicit colormap per rules\n",
        "plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
        "plt.yticks(range(len(corr.columns)), corr.columns)\n",
        "plt.title(\"Correlation Heatmap of Numeric Features\")\n",
        "plt.colorbar(label=\"Correlation\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG1, dpi=300, bbox_inches=\"tight\")\n",
        "plt.close()\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# 3) EDA: Funding distribution by school type (boxplot)\n",
        "# -------------------------------------------------------\n",
        "if \"school_type\" in df.columns and \"funding_per_student_usd\" in df.columns:\n",
        "    grouped = [\n",
        "        df.loc[df[\"school_type\"] == cat, \"funding_per_student_usd\"].dropna().values\n",
        "        for cat in df[\"school_type\"].dropna().unique()\n",
        "    ]\n",
        "    labels = df[\"school_type\"].dropna().unique().tolist()\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.boxplot(grouped, labels=labels, showmeans=True)\n",
        "    plt.title(\"Funding per Student across School Types\")\n",
        "    plt.ylabel(\"Funding per Student (USD)\")\n",
        "    plt.xlabel(\"School Type\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(FIG2, dpi=300, bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# 4) Create target labels: dropout risk categories (quantile-based)\n",
        "# -------------------------------------------------------\n",
        "drop_col = \"dropout_rate_percent\"\n",
        "if drop_col not in df.columns:\n",
        "    raise KeyError(\"Expected column 'dropout_rate_percent' not found in dataset.\")\n",
        "\n",
        "df = df.dropna(subset=[drop_col]).copy()\n",
        "df[\"dropout_risk_cat\"] = pd.qcut(df[drop_col], q=3, labels=[\"low\", \"medium\", \"high\"])\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# 5) Feature engineering: numeric + categorical\n",
        "# -------------------------------------------------------\n",
        "exclude_cols = [\"id\", \"school_name\", \"state\", \"dropout_rate_percent\", \"dropout_risk_cat\"]\n",
        "feature_cols = [c for c in df.columns if c not in exclude_cols]\n",
        "\n",
        "X = df[feature_cols].copy()\n",
        "y = df[\"dropout_risk_cat\"].copy()\n",
        "\n",
        "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), numeric_features),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# 6) Split data\n",
        "# -------------------------------------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# 7) Model: Random Forest\n",
        "# -------------------------------------------------------\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "pipe = Pipeline(steps=[(\"prep\", preprocess), (\"rf\", rf)])\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# 8) Evaluation\n",
        "# -------------------------------------------------------\n",
        "y_pred = pipe.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
        "rec = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
        "\n",
        "print(\"Accuracy:\", acc)\n",
        "print(\"Precision (macro):\", prec)\n",
        "print(\"Recall (macro):\", rec)\n",
        "print(\"F1 (macro):\", f1)\n",
        "print()\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "# Save classification report\n",
        "with open(REPORT_TXT, \"w\") as f:\n",
        "    f.write(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred, labels=[\"low\", \"medium\", \"high\"])\n",
        "cm_df = pd.DataFrame(\n",
        "    cm,\n",
        "    index=[\"true_low\", \"true_medium\", \"true_high\"],\n",
        "    columns=[\"pred_low\", \"pred_medium\", \"pred_high\"]\n",
        ")\n",
        "cm_df.to_csv(CM_CSV, index=True)\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# 9) Plot metrics bar chart (fig3)\n",
        "# -------------------------------------------------------\n",
        "metrics = {\n",
        "    \"accuracy\": acc,\n",
        "    \"precision_macro\": prec,\n",
        "    \"recall_macro\": rec,\n",
        "    \"f1_macro\": f1\n",
        "}\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.bar(list(metrics.keys()), list(metrics.values()))\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"Random Forest Performance (Test Set)\")\n",
        "plt.xticks(rotation=30)\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG3, dpi=300, bbox_inches=\"tight\")\n",
        "plt.close()\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# 10) Feature importances export (CSV)\n",
        "# -------------------------------------------------------\n",
        "# Retrieve generated feature names from preprocessors\n",
        "ohe = pipe.named_steps[\"prep\"].named_transformers_[\"cat\"]\n",
        "cat_names = list(ohe.get_feature_names_out(categorical_features)) if categorical_features else []\n",
        "all_feature_names = numeric_features + cat_names\n",
        "\n",
        "importances = pipe.named_steps[\"rf\"].feature_importances_\n",
        "feat_imp_df = pd.DataFrame({\"feature\": all_feature_names, \"importance\": importances})\n",
        "feat_imp_df = feat_imp_df.sort_values(\"importance\", ascending=False)\n",
        "feat_imp_df.to_csv(FEATIMP_CSV, index=False)\n",
        "\n",
        "print(\"\\nSaved:\")\n",
        "print(\"-\", FIG1)\n",
        "print(\"-\", FIG2)\n",
        "print(\"-\", FIG3)\n",
        "print(\"-\", REPORT_TXT)\n",
        "print(\"-\", CM_CSV)\n",
        "print(\"-\", FEATIMP_CSV)\n"
      ]
    }
  ]
}